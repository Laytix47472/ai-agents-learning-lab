# ğŸ” Aprendizado por ReforÃ§o â€“ Treinamento com Ambientes (OpenAI Gym)

Agentes por reforÃ§o aprendem com tentativa e erro, recebendo **recompensas** com base no desempenho em um ambiente simulado.

---

## ğŸ”§ Frameworks usados

| Framework | FunÃ§Ã£o                              |
|-----------|-------------------------------------|
| Gym       | Ambientes de simulaÃ§Ã£o padrÃ£o       |
| Ray RLlib | Treinamento distribuÃ­do de RL       |
| PettingZoo | Multiagentes para RL               |

---

## ğŸ§ª Exemplo: CartPole com Gym + RLlib

```python
import gym
from ray.rllib.algorithms.ppo import PPO

env = gym.make("CartPole-v1")
algo = PPO(env="CartPole-v1")
results = algo.train()
```
---

## ğŸ¯ Recompensas

O agente aprende atravÃ©s de feedback (positivo ou negativo), por exemplo:

- +1 se mantÃ©m o poste em pÃ©
- -1 se ele cai
---

## ğŸ“ CÃ³digo
```txt
models/reinforcement/cartpole_ppo.py
```
---

## ğŸ¤– Uso em Agentes

Agentes treinados por reforÃ§o sÃ£o usados em:

- DecisÃ£o tÃ¡tica e estratÃ©gica
- NavegaÃ§Ã£o autÃ´noma
- Aprendizado por reforÃ§o com feedback humano (RLHF)

---
